{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Av4QnUZFCiO0",
        "awbA0B4rCsEP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UNDUH DATA"
      ],
      "metadata": {
        "id": "Av4QnUZFCiO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c7lxcbICUW5",
        "outputId": "16dd929e-84a5-4312-ac59-15d0f49a9191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-02 03:22:57--  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip [following]\n",
            "--2024-01-02 03:22:57--  https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M  63.1MB/s    in 0.9s    \n",
            "\n",
            "2024-01-02 03:23:01 (63.1 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "    -O /tmp/Chessman-image-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EKSTRAKSI FILE ZIP"
      ],
      "metadata": {
        "id": "awbA0B4rCsEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=0.1) # set validation split"
      ],
      "metadata": {
        "id": "TIloHdqlCwcU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLITTING DATA TRAIN DAN DATA TEST USING VALIDATION SET FUNCTION"
      ],
      "metadata": {
        "id": "2wjL9f1oFADN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoNw2DEaFC5i",
        "outputId": "1e39a7f4-423b-426a-e070-c68c1b8a1a93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 499 images belonging to 6 classes.\n",
            "Found 52 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUAT MODEL DG TRANSFER LEARNING DG MEMANGGIL KELAS RESTNET152V2"
      ],
      "metadata": {
        "id": "HmU8tir8FfCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "model = tf.keras.models.Sequential([\n",
        "    ResNet152V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(150, 150, 3))),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNI1W-8IMjwH",
        "outputId": "3f291c0a-16d8-4ce0-8158-07f97d2daa1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234545216/234545216 [==============================] - 9s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight : ini adalah bobot atau parameter seperti yang telah dibahas pada kelas machine learning pemula. Untuk parameter weight kita mengisi nilai ‘imagenet’. Artinya kita ingin menggunakan model ResNet152V2 yang telah dilatih pada dataset imagenet. Imagenet adalah sebuah database raksasa yang berisi lebih dari 14 juta gambar.\n",
        "\n",
        "\n",
        "Include_top : parameter ini bernilai boolean. Maksud dari parameter ini apabila kita ingin tetap memakai layer terakhir/layer prediksi dari model resnet. Kita isi false karena kita memakai model resnet untuk memprediksi dataset chessman bukan imagenet.\n",
        "\n",
        "\n",
        "Input_tensor : sesuai namanya parameter ini menspesifikasikan ukuran dari input."
      ],
      "metadata": {
        "id": "I_yofu5uMtYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MENENTUKAN OPTIMAZER DAN LOSS"
      ],
      "metadata": {
        "id": "3i7CSN4wM7tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "cUdaxPP_M2a-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LATIH MODEL"
      ],
      "metadata": {
        "id": "WoQqPtGRNDzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              epochs=50,\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1i4k0AnNFFD",
        "outputId": "1bba2c07-b659-4001-9095-b0f20454438f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 179s - loss: 9.7665 - accuracy: 0.4208 - val_loss: 8.7891 - val_accuracy: 0.3654 - 179s/epoch - 3s/step\n",
            "Epoch 2/50\n",
            "63/63 - 175s - loss: 2.0154 - accuracy: 0.6693 - val_loss: 1.2850 - val_accuracy: 0.7885 - 175s/epoch - 3s/step\n",
            "Epoch 3/50\n",
            "63/63 - 172s - loss: 0.7849 - accuracy: 0.7996 - val_loss: 2.0829 - val_accuracy: 0.5962 - 172s/epoch - 3s/step\n",
            "Epoch 4/50\n",
            "63/63 - 171s - loss: 1.1368 - accuracy: 0.7816 - val_loss: 1.2492 - val_accuracy: 0.6731 - 171s/epoch - 3s/step\n",
            "Epoch 5/50\n",
            "63/63 - 180s - loss: 0.9587 - accuracy: 0.7735 - val_loss: 1.4311 - val_accuracy: 0.6731 - 180s/epoch - 3s/step\n",
            "Epoch 6/50\n",
            "63/63 - 172s - loss: 0.8519 - accuracy: 0.8076 - val_loss: 0.8844 - val_accuracy: 0.8269 - 172s/epoch - 3s/step\n",
            "Epoch 7/50\n",
            "63/63 - 173s - loss: 0.7918 - accuracy: 0.8317 - val_loss: 1.0744 - val_accuracy: 0.6923 - 173s/epoch - 3s/step\n",
            "Epoch 8/50\n",
            "63/63 - 177s - loss: 0.6597 - accuracy: 0.8457 - val_loss: 0.7835 - val_accuracy: 0.6923 - 177s/epoch - 3s/step\n",
            "Epoch 9/50\n",
            "63/63 - 174s - loss: 0.6373 - accuracy: 0.8737 - val_loss: 1.8052 - val_accuracy: 0.6731 - 174s/epoch - 3s/step\n",
            "Epoch 10/50\n",
            "63/63 - 172s - loss: 0.3683 - accuracy: 0.9018 - val_loss: 0.9841 - val_accuracy: 0.7308 - 172s/epoch - 3s/step\n",
            "Epoch 11/50\n",
            "63/63 - 172s - loss: 0.4494 - accuracy: 0.8878 - val_loss: 1.3298 - val_accuracy: 0.7500 - 172s/epoch - 3s/step\n",
            "Epoch 12/50\n",
            "63/63 - 179s - loss: 0.7303 - accuracy: 0.8557 - val_loss: 1.5661 - val_accuracy: 0.6923 - 179s/epoch - 3s/step\n",
            "Epoch 13/50\n"
          ]
        }
      ]
    }
  ]
}